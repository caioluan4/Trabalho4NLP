{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "print(\"Configurando o ambiente para leitura de arquivos locais...\")\n",
        "\n",
        "PATH_TABLES = 'tables.json'\n",
        "PATH_TRAIN_DATA = 'train_spider.json'\n",
        "PATH_DEV_DATA = 'dev.json'\n",
        "\n",
        "TRAIN_OUTPUT_FILE = 'train_formatted.jsonl'\n",
        "DEV_OUTPUT_FILE = 'dev_formatted.jsonl'\n",
        "\n",
        "print(\"Caminhos definidos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maoqXFLS15cP",
        "outputId": "e2e9d30e-45a4-42bd-f8be-73786baa1bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando o ambiente para leitura de arquivos locais...\n",
            "Caminhos definidos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_schemas_from_tables_json(path_to_tables_json):\n",
        "    \"\"\"LÃª o arquivo tables.json e gera um dicionÃ¡rio de schemas.\"\"\"\n",
        "    print(f\"Gerando dicionÃ¡rio de schemas a partir de '{path_to_tables_json}'...\")\n",
        "    try:\n",
        "        with open(path_to_tables_json, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERRO: Arquivo '{path_to_tables_json}' nÃ£o encontrado!\")\n",
        "        print(\"Certifique-se de que vocÃª fez o upload do arquivo 'tables.json' para o ambiente.\")\n",
        "        return None\n",
        "\n",
        "    schemas_dict = {}\n",
        "    for db_info in data:\n",
        "        db_id = db_info['db_id']\n",
        "        table_names = db_info['table_names_original']\n",
        "        columns_info = db_info['column_names_original']\n",
        "        column_types = db_info['column_types']\n",
        "        primary_keys_indices = db_info['primary_keys']\n",
        "        db_schema_parts = []\n",
        "        column_details = {i: (columns_info[i][1], column_types[i]) for i in range(len(columns_info))}\n",
        "\n",
        "        for i, table_name in enumerate(table_names):\n",
        "            table_creation_string = f\"CREATE TABLE `{table_name}` (\\n\"\n",
        "            table_columns = []\n",
        "            for col_idx, (tbl_idx, col_name) in enumerate(columns_info):\n",
        "                if tbl_idx == i:\n",
        "                    col_type = column_types[col_idx]\n",
        "                    table_columns.append(f\"  `{col_name}` {col_type.upper()}\")\n",
        "            table_creation_string += \",\\n\".join(table_columns)\n",
        "            pk_cols = []\n",
        "            for pk_index in primary_keys_indices:\n",
        "                if columns_info[pk_index][0] == i:\n",
        "                    pk_col_name = column_details[pk_index][0]\n",
        "                    pk_cols.append(f\"`{pk_col_name}`\")\n",
        "            if pk_cols:\n",
        "                table_creation_string += f\",\\n  PRIMARY KEY ({', '.join(pk_cols)})\"\n",
        "            table_creation_string += \"\\n);\"\n",
        "            db_schema_parts.append(table_creation_string)\n",
        "        schemas_dict[db_id] = \"\\n\".join(db_schema_parts)\n",
        "\n",
        "    print(f\"DicionÃ¡rio de schemas gerado com sucesso com {len(schemas_dict)} entradas.\")\n",
        "    return schemas_dict"
      ],
      "metadata": {
        "id": "uSKeLBv816vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_and_save_local_json(input_json_path, schema_dict, output_file):\n",
        "    \"\"\"\n",
        "    LÃª um arquivo JSON local do Spider, formata-o em prompts de texto\n",
        "    e salva o resultado em um arquivo JSON Lines (.jsonl) com a codificaÃ§Ã£o correta.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Processando o arquivo local: '{input_json_path}' ---\")\n",
        "\n",
        "    try:\n",
        "        with open(input_json_path, 'r') as f:\n",
        "            local_data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERRO: Arquivo de dados '{input_json_path}' nÃ£o encontrado!\")\n",
        "        print(f\"Certifique-se de que vocÃª fez o upload do arquivo.\")\n",
        "        return\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "   You are an expert model specializing in the task of converting natural language text into SQL queries. Your role is to answer user questions by generating syntactically correct SQL queries based on the provided database schema. Your response must be solely the SQL query corresponding to the natural language text. Generate the SQL query in a single line. Do not insert line breaks within the generated query. Use ONLY the tables and columns provided in the â€˜Database Schemaâ€™ section, referring to them correctly. Do not make up column or table names. Use table aliases (e.g., T1, T2) only when a JOIN operation between multiple tables is required, either to disambiguate columns with the same name or to improve clarity. For queries involving a single table, do not use aliases. Refer to the examples below to understand how you should respond. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "    ### Examples of expected output:\n",
        "\n",
        "    1.\n",
        "      - schema example: 'CREATE TABLE trip (end_station_id VARCHAR); CREATE TABLE station (id VARCHAR, city VARCHAR)'\n",
        "      - natural language text: 'Count the number of trips that did not end in San Francisco city.'\n",
        "      - expected SQL query: 'SELECT COUNT(*) FROM trips WHERE end_city != 'San Francisco'\n",
        "    2.\n",
        "      - schema example: 'CREATE TABLE Aircraft (aid VARCHAR, distance INTEGER)'\n",
        "      - natural language text: 'Show ids for all aircrafts with more than 1000 distance.'\n",
        "      - expected SQL query: 'SELECT aid FROM Aircraft WHERE distance > 1000'\n",
        "    3.\n",
        "      - schema example: 'CREATE TABLE actor (Musical_ID VARCHAR); CREATE TABLE musical (Name VARCHAR, Musical_ID VARCHAR)'\n",
        "      - natural language text: 'Show names of musicals which have at least three actors.'\n",
        "      - expected SQL query: 'SELECT T2.Name FROM actor AS T1 JOIN musical AS T2 ON T1.Musical_ID = T2.Musical_ID GROUP BY T1.Musical_ID HAVING COUNT(*) >= 3'\n",
        "\n",
        "    ### Database Schema:\n",
        "    {schema}\n",
        "\n",
        "    ### Question:\n",
        "    {question}\n",
        "\n",
        "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "    {sql_query}<|eot_id|>\"\"\"\n",
        "\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
        "        for example in local_data:\n",
        "            db_id = example['db_id']\n",
        "            schema = schema_dict.get(db_id, \"\")\n",
        "            if not schema:\n",
        "                print(f\"AVISO: Schema para o db_id '{db_id}' nÃ£o encontrado.\")\n",
        "\n",
        "            prompt_full = PROMPT_TEMPLATE.format(\n",
        "                schema=schema,\n",
        "                question=example['question'],\n",
        "                sql_query=example['query']\n",
        "            )\n",
        "\n",
        "            line_obj = {'text': prompt_full}\n",
        "\n",
        "            f_out.write(json.dumps(line_obj, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    print(f\"Total de exemplos processados: {len(local_data)}\")"
      ],
      "metadata": {
        "id": "xTdHsta05POM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_schema_dict = generate_schemas_from_tables_json(PATH_TABLES)\n",
        "\n",
        "if master_schema_dict:\n",
        "\n",
        "    format_and_save_local_json(\n",
        "        input_json_path=PATH_TRAIN_DATA,\n",
        "        schema_dict=master_schema_dict,\n",
        "        output_file=TRAIN_OUTPUT_FILE\n",
        "    )\n",
        "\n",
        "    format_and_save_local_json(\n",
        "        input_json_path=PATH_DEV_DATA,\n",
        "        schema_dict=master_schema_dict,\n",
        "        output_file=DEV_OUTPUT_FILE\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R17xkyTo199C",
        "outputId": "e72806fc-71ca-4f76-aa8c-f38bf824ad27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando dicionÃ¡rio de schemas a partir de 'tables.json'...\n",
            "DicionÃ¡rio de schemas gerado com sucesso com 166 entradas.\n",
            "\n",
            "--- Processando o arquivo local: 'train_spider.json' ---\n",
            "âœ… Arquivo 'train_spider.json' formatado e salvo com sucesso em 'train_formatted.jsonl'\n",
            "Total de exemplos processados: 7000\n",
            "\n",
            "--- Processando o arquivo local: 'dev.json' ---\n",
            "âœ… Arquivo 'dev.json' formatado e salvo com sucesso em 'dev_formatted.jsonl'\n",
            "Total de exemplos processados: 1034\n",
            "\n",
            "ðŸŽ‰ Processo concluÃ­do! Seus arquivos formatados estÃ£o prontos.\n"
          ]
        }
      ]
    }
  ]
}